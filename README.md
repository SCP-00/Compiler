# Lexer para un Lenguaje de Programaci√≥n
### Integrantes
- Victor Alejandro Buendia Henao
- Juan Sebasti√°n valencia Uribe
- Jose David Marin
Este proyecto es un **analizador l√©xico** (lexer) escrito en Python. Su funci√≥n es tomar un fragmento de c√≥digo fuente y descomponerlo en **tokens**, que son las unidades fundamentales del lenguaje.

## üì¶ Archivos clave:

- **UTP_lexer.py**: Este archivo descompone el c√≥digo en tokens usando expresiones regulares, manejando identificadores, operadores y literales. ¬°Tambi√©n detecta errores como caracteres ilegales! üßê
  
- **UTP_parser.py**: Se encarga de organizar los tokens en estructuras l√≥gicas y generar nodos AST que representan el c√≥digo en un formato m√°s comprensible para la m√°quina. üéØ

- **UTP_AST_nodes.py**: Aqu√≠ es donde definimos los diferentes nodos del AST que representan operaciones como literales, declaraciones de variables, operaciones binarias, y m√°s. üí°

- **UTP_error_handler.py**: Administra los errores que se encuentran durante el an√°lisis del c√≥digo y los muestra de manera clara y comprensible. ‚ùå

## üìå Caracter√≠sticas

- Soporta palabras reservadas como `var`, `if`, `while`, `return`, etc.
- Identifica operadores (`+`, `-`, `*`, `<=`, `==`, etc.)
- Reconoce identificadores, n√∫meros enteros, flotantes y caracteres
- Soporta comentarios de l√≠nea (`//`) y de bloque (`/* ... */`)
- Ignora espacios en blanco
- Detecta caracteres ilegales

---

## üìú Ejemplo de C√≥digo de Entrada

El lexer analiza c√≥digo como este:

```
var x = 10;
if (x >= 5) {
    print(x);
}
```

### üîç Tokens Generados

El c√≥digo anterior se convierte en la siguiente lista de tokens:

```
Token(type='VAR', value='var', lineno=1)
Token(type='ID', value='x', lineno=1)
Token(type='ASSIGN', value='=', lineno=1)
Token(type='INTEGER', value='10', lineno=1)
Token(type='SEMI', value=';', lineno=1)
Token(type='IF', value='if', lineno=2)
Token(type='LPAREN', value='(', lineno=2)
Token(type='ID', value='x', lineno=2)
Token(type='GE', value='>=', lineno=2)
Token(type='INTEGER', value='5', lineno=2)
Token(type='RPAREN', value=')', lineno=2)
Token(type='LBRACE', value='{', lineno=2)
Token(type='PRINT', value='print', lineno=3)
Token(type='LPAREN', value='(', lineno=3)
Token(type='ID', value='x', lineno=3)
Token(type='RPAREN', value=')', lineno=3)
Token(type='SEMI', value=';', lineno=3)
Token(type='RBRACE', value='}', lineno=4)
```

---

## C√≥mo Usarlo?

Para ejecutar el lexer, simplemente corre el script en Python:

```bash
python lexer.py
```

Si dentro del c√≥digo fuente hay caracteres ilegales, el lexer los detecta y muestra un error. Por ejemplo, si el c√≥digo contiene `var b = @20;`, la salida incluir√°:

```
L√≠nea 2: Error - Caracter ilegal '@'
```

---

## üõ† Estructura del C√≥digo

El lexer usa expresiones regulares para identificar distintos tipos de tokens. Los pasos clave son:

1. Definir los **patrones de tokens** en `TOKEN_SPEC` para categorizar su clase.
2. Crear una **expresi√≥n regular combinada**.
3. Usar `re.finditer()` para recorrer el c√≥digo fuente y generar una lista de tokens.
4. Ignorar espacios en blanco y comentarios.
5. Detectar errores de caracteres ilegales.

---

## üìù Nota

- Es un lexer b√°sico, no un parser y mucho menos un compilador completo. No verifica la sintaxis completa, solo descompone el c√≥digo en tokens.
- Se puede ampliar f√°cilmente agregando m√°s palabras clave u operadores como por ejemplo el uso de un token **CLASSES**.

# Universidad Tecnologica de Pereira
## 2025-1
### Ingenieria de Sistemas // Clase Compiladores IS75
### Docente: Angel Augusto Agudelo Zapata
